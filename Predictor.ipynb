{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo la librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5850 entries, 0 to 5849\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            5850 non-null   int64  \n",
      " 1   id                    5850 non-null   object \n",
      " 2   title                 5849 non-null   object \n",
      " 3   type                  5850 non-null   object \n",
      " 4   description           5832 non-null   object \n",
      " 5   release_year          5850 non-null   int64  \n",
      " 6   age_certification     3231 non-null   object \n",
      " 7   runtime               5850 non-null   int64  \n",
      " 8   genres                5850 non-null   object \n",
      " 9   production_countries  5850 non-null   object \n",
      " 10  seasons               2106 non-null   float64\n",
      " 11  imdb_id               5447 non-null   object \n",
      " 12  imdb_score            5850 non-null   float64\n",
      " 13  imdb_votes            5352 non-null   float64\n",
      " 14  tmdb_popularity       5759 non-null   float64\n",
      " 15  tmdb_score            5850 non-null   float64\n",
      "dtypes: float64(5), int64(3), object(8)\n",
      "memory usage: 731.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#importo el dataset y hago revision de los datos\n",
    "\n",
    "df = pd.read_csv(\"titles_filtrado.csv\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo en X e Y\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import string\n",
    "punctuation = set(string.punctuation)\n",
    "def tokenize(sentence):\n",
    "    tokens = []\n",
    "    for token in sentence.split():\n",
    "        new_token = []\n",
    "        for character in token:\n",
    "            if character not in punctuation:\n",
    "                new_token.append(character.lower())\n",
    "        if new_token:\n",
    "            tokens.append(\"\".join(new_token))\n",
    "    return tokens\n",
    "\n",
    "demo_vectorizer = CountVectorizer(\n",
    "    tokenizer = tokenize,\n",
    "    binary = True\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "df_sklearn = df.drop([  \"description\",\n",
    "                        \"age_certification\",\n",
    "                        \"title\",\n",
    "                        \"seasons\",\n",
    "                        \"imdb_id\",\n",
    "#                        \"imdb_votes\",\n",
    "#                        \"tmdb_popularity\",\n",
    "#                        \"tmdb_score\",\n",
    "#                        \"production_countries\",\n",
    "                        \"id\"], axis=1) #Elimino de mi dataset la variable a predecir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnumeric_features.remove(\"title_year\") \\ncategorical_features.append(\"title_year\")\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features=df_sklearn._get_numeric_data().columns.values.tolist()\n",
    "\n",
    "text_features=df_sklearn.columns.values.tolist()\n",
    "text_features=[i for i in text_features if i not in numeric_features]\n",
    "\n",
    "string_features=[\"age_certification\", \"production_countries\"]\n",
    "\n",
    "categorical_features=[i for i in text_features if i not in string_features]\n",
    "\"\"\"\n",
    "numeric_features.remove(\"title_year\") \n",
    "categorical_features.append(\"title_year\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los valores por valores numericos\n",
    "type_numerico = {'SHOW' : 1, 'MOVIE' : 0 }\n",
    "\"\"\"\n",
    "age_certification_numerico = {  \"TV-MA\" :   0,\n",
    "                                \"R\"     :   1,\n",
    "                                \"TV-14\" :   2,\n",
    "                                \"PG-13\" :   3,\n",
    "                                \"PG\"    :   4,\n",
    "                                \"TV-PG\" :   5,\n",
    "                                \"G\"     :   6,\n",
    "                                \"TV-Y7\" :   7,\n",
    "                                \"TV-Y\"  :   8,\n",
    "                                \"TV-G\"  :   9,\n",
    "                                \"NC-17\" :   10 }\n",
    "\"\"\"\n",
    "genres_numerico = { \"'drama'\"         :   0,\n",
    "                    \"'comedy'\"        :   1,\n",
    "                    \"'thriller'\"      :   2,\n",
    "                    \"'action'\"        :   3,\n",
    "                    \"'romance'\"       :   4,\n",
    "                    \"'documentation'\" :   5,\n",
    "                    \"'crime'\"         :   6,\n",
    "                    \"'animation'\"     :   7,\n",
    "                    \"'family'\"        :   8,\n",
    "                    \"'fantasy'\"       :   9,\n",
    "                    \"'scifi'\"         :   10,\n",
    "                    \"'european'\"      :   11,\n",
    "                    \"'horror'\"        :   12,\n",
    "                    \"'music'\"         :   13,\n",
    "                    \"'history'\"       :   14,\n",
    "                    \"'reality'\"       :   15,\n",
    "                    \"'sport'\"         :   16,\n",
    "                    \"'war'\"           :   17,\n",
    "                    \"'western'\"       :   18  }\n",
    "\n",
    "\"\"\"production_countries_numerico = {   \"'US'\"  :   0,\n",
    "                                    \"'IN'\"  :   1,\n",
    "                                    \"'GB'\"  :   2,\n",
    "                                    \"'JP'\"  :   3,\n",
    "                                    \"'FR'\"  :   4,\n",
    "                                    \"'KR'\"  :   5,\n",
    "                                    \"'CA'\"  :   6,\n",
    "                                    \"'ES'\"  :   7,\n",
    "                                    \"'DE'\"  :   8,\n",
    "                                    \"'MX'\"  :   9,\n",
    "                                    \"'CN'\"  :   10,\n",
    "                                    \"'BR'\"  :   11,\n",
    "                                    \"'PH'\"  :   12,\n",
    "                                    \"'TR'\"  :   13,\n",
    "                                    \"'AU'\"  :   14,\n",
    "                                    \"'IT'\"  :   15,\n",
    "                                    \"'NG'\"  :   16,\n",
    "                                    \"'AR'\"  :   17,\n",
    "                                    \"'TW'\"  :   18,\n",
    "                                    \"'ID'\"  :   19,\n",
    "                                    \"'BE'\"  :   20,\n",
    "                                    \"'EG'\"  :   21,\n",
    "                                    \"'CO'\"  :   22,\n",
    "                                    \"'ZA'\"  :   23,\n",
    "                                    \"'PL'\"  :   24,\n",
    "                                    \"'NL'\"  :   25,\n",
    "                                    \"'LB'\"  :   26,\n",
    "                                    \"'HK'\"  :   27,\n",
    "                                    \"'TH'\"  :   28,\n",
    "                                    \"'DK'\"  :   29,  }\n",
    "\n",
    "#X = X[X[\"genres\"] == production_countries_numerico]\n",
    "X_filtrado_countries = X['production_countries'].value_counts().head(30).index\n",
    "#X.replace({'production_countries' : production_countries_numerico }, inplace=True, regex=True)\n",
    "#X = X[X[\"genres\"] != \"[]\"]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#df_sklearn.replace({'genres' : genres_numerico }, inplace=True, regex=True)\n",
    "#df_sklearn = df_sklearn[df_sklearn[\"genres\"] != \"[]\"]\n",
    "df_sklearn.replace({'type' : type_numerico }, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   type  release_year  runtime  \\\n",
      "0           0   SHOW          1945       51   \n",
      "1           1  MOVIE          1976      114   \n",
      "2           2  MOVIE          1972      109   \n",
      "3           3  MOVIE          1975       91   \n",
      "4           4  MOVIE          1967      150   \n",
      "\n",
      "                                        genres production_countries  \\\n",
      "0                            ['documentation']               ['US']   \n",
      "1                           ['drama', 'crime']               ['US']   \n",
      "2  ['drama', 'action', 'thriller', 'european']               ['US']   \n",
      "3              ['fantasy', 'action', 'comedy']               ['GB']   \n",
      "4                            ['war', 'action']         ['GB', 'US']   \n",
      "\n",
      "   imdb_votes  tmdb_popularity  tmdb_score  \n",
      "0         NaN            0.600         6.8  \n",
      "1    808582.0           40.965         8.2  \n",
      "2    107673.0           10.010         7.3  \n",
      "3    534486.0           15.461         7.8  \n",
      "4     72662.0           20.398         7.6  \n",
      "0    6.5\n",
      "1    8.2\n",
      "2    7.7\n",
      "3    8.2\n",
      "4    7.7\n",
      "Name: imdb_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_sklearn.dropna(axis= 0, how='any')\n",
    "\n",
    "X = df_sklearn.drop(\"imdb_score\", axis=1)\n",
    "print(X.head())\n",
    "y = df_sklearn.imdb_score #Defino el Target\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Me quedo con 30% para test y 70% para train\n",
    "\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(df_sklearn[\"production_countries\"], \n",
    "                                                                    df_sklearn[\"genres\"])\n",
    "real_vectorizer = CountVectorizer(tokenizer = tokenize, binary=True)\n",
    "train_X = real_vectorizer.fit_transform(train_text)\n",
    "test_X = real_vectorizer.transform(test_text)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSimpleImputer does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ezesp\\CoderHouse\\GitHub\\Proyecto_Final_Grupo3_DS29765\\Predictor.ipynb Celda 8\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## we use standard scaler to keep as much variance as possible (compared to minmax)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m imp\u001b[39m=\u001b[39mSimpleImputer(missing_values\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNaN\u001b[39m\u001b[39m'\u001b[39m,strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmost_frequent\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_sklearn[numeric_features]\u001b[39m=\u001b[39mimp\u001b[39m.\u001b[39;49mfit_transform(df_sklearn[numeric_features])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scl\u001b[39m=\u001b[39mStandardScaler()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df_sklearn[numeric_features]\u001b[39m=\u001b[39mscl\u001b[39m.\u001b[39mfit_transform(df_sklearn[numeric_features])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\impute\\_base.py:364\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    356\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    357\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter was deprecated in version \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    362\u001b[0m     )\n\u001b[1;32m--> 364\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(X, in_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    366\u001b[0m \u001b[39m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m# otherwise\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\impute\\_base.py:319\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[39mraise\u001b[39;00m new_ve \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    318\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m         \u001b[39mraise\u001b[39;00m ve\n\u001b[0;32m    321\u001b[0m \u001b[39mif\u001b[39;00m in_fit:\n\u001b[0;32m    322\u001b[0m     \u001b[39m# Use the dtype seen in `fit` for non-`fit` conversion\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_dtype \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\impute\\_base.py:302\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    299\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    303\u001b[0m         X,\n\u001b[0;32m    304\u001b[0m         reset\u001b[39m=\u001b[39;49min_fit,\n\u001b[0;32m    305\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    306\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    307\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    308\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[0;32m    309\u001b[0m     )\n\u001b[0;32m    310\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m ve:\n\u001b[0;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcould not convert\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(ve):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSimpleImputer does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "## we use standard scaler to keep as much variance as possible (compared to minmax)\n",
    "\n",
    "imp=SimpleImputer(missing_values='NaN',strategy=\"most_frequent\")\n",
    "df_sklearn[numeric_features]=imp.fit_transform(df_sklearn[numeric_features])\n",
    "\n",
    "scl=StandardScaler()\n",
    "df_sklearn[numeric_features]=scl.fit_transform(df_sklearn[numeric_features])\n",
    "\n",
    "df_sklearn[numeric_features].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier #Importo el modelo\n",
    "\n",
    "clf = tree.DecisionTreeRegressor(max_depth=2, random_state = 42) #Creo el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno el modelo\n",
    "\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ezesp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"['US']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ezesp\\CoderHouse\\GitHub\\Proyecto_Final_Grupo3_DS29765\\Predictor.ipynb Celda 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_train_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(train_text) \u001b[39m#Prediccion en Train\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ezesp/CoderHouse/GitHub/Proyecto_Final_Grupo3_DS29765/Predictor.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_test_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(test_text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:505\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[0;32m    506\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    507\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:471\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    472\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    473\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[0;32m    474\u001b[0m     ):\n\u001b[0;32m    475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:872\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m    826\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[39m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m \u001b[39m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"['US']\""
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(train_text) #Prediccion en Train\n",
    "y_test_pred = clf.predict(test_text) #Prediccion en Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bfb2b3bd7df5c81aa15934e65570dceb366a496b1d88c1199517baba9f2df6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
